{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de python, para especificar rutas de archivos y directorios\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "# lib para trabajar con arrays\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "# lib que usamos para mostrar las imágenes\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# libs que usamos para construir y entrenar redes neuronales, y que además tiene utilidades para leer sets de \n",
    "# imágenes\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Convolution2D, MaxPooling2D, Flatten, Rescaling\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "\n",
    "# libs que usamos para tareas generales de machine learning. En este caso, métricas\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# configuración para que las imágenes se vean dentro del notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AMBIENTE DE TEST Y TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "'''\n",
    "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
    "(X_train, Y_train) = train \n",
    "(X_test, Y_test) = test\n",
    "'''\n",
    "train, test = fashion_mnist.load_data()\n",
    "(X_train, Y_train) = train \n",
    "(X_test, Y_test) = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCIONES DE BUSSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "# Fit model\n",
    "def fit_model(model, epochs=EPOCHS, batch_size=BATCH_SIZE, plot_model=True):\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        epochs = epochs,\n",
    "        batch_size = batch_size,\n",
    "        validation_data=(X_test, Y_test),\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Plot train and validation accuracy of up to three models\n",
    "def plot_model(model_1, model_2=None, model_3=None, loss=False, title='', subtitle_1='', subtitle_2='', subtitle_3='', epochs=EPOCHS):\n",
    "    if loss:\n",
    "        ylabel = 'Loss'\n",
    "        train_metric = 'loss'\n",
    "        validation_metric = 'val_loss'\n",
    "    else:\n",
    "        ylabel = 'Accuracy'\n",
    "        train_metric = 'accuracy'\n",
    "        validation_metric = 'val_accuracy'\n",
    "\n",
    "    if model_2 is None and model_3 is None:\n",
    "        plt.figure(figsize=(7, 5)) \n",
    "        plt.title(title)\n",
    "        plt.plot(model_1.history[train_metric], label='train')\n",
    "        plt.plot(model_1.history[validation_metric], label='validation')\n",
    "        if epochs <= 20:\n",
    "            plt.xticks(np.arange(epochs), np.arange(1, epochs+1))\n",
    "        else:\n",
    "            original_ticks_list = np.arange(epochs)\n",
    "            # Just 3 ticks (min, half, max)\n",
    "            new_ticks_list = [min(original_ticks_list), original_ticks_list[math.floor(len(original_ticks_list)/2)], max(original_ticks_list)]\n",
    "            new_ticks_label_list = [min(original_ticks_list+1), original_ticks_list[math.floor(len(original_ticks_list)/2)], max(original_ticks_list)+1]\n",
    "            plt.xticks(new_ticks_list, new_ticks_label_list)\n",
    "       \n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(loc='best')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        if model_3 is None:\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(15.3, 5))\n",
    "            fig.suptitle(title)\n",
    "            ax1.title.set_text(subtitle_1)\n",
    "            ax2.title.set_text(subtitle_2)\n",
    "            ax1.plot(model_1.history[train_metric], label='train')\n",
    "            ax2.plot(model_2.history[train_metric], label='train')\n",
    "            ax1.plot(model_1.history[validation_metric], label='validation')\n",
    "            ax2.plot(model_2.history[validation_metric], label='validation')\n",
    "\n",
    "            axes_list = [ax1, ax2]\n",
    "\n",
    "        else:\n",
    "            fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True, figsize=(24, 5))\n",
    "            fig.suptitle(title)\n",
    "            ax1.title.set_text(subtitle_1)\n",
    "            ax2.title.set_text(subtitle_2)\n",
    "            ax3.title.set_text(subtitle_3)\n",
    "            ax1.plot(model_1.history[train_metric], label='train')\n",
    "            ax2.plot(model_2.history[train_metric], label='train')\n",
    "            ax3.plot(model_3.history[train_metric], label='train')\n",
    "            ax1.plot(model_1.history[validation_metric], label='validation')\n",
    "            ax2.plot(model_2.history[validation_metric], label='validation')\n",
    "            ax3.plot(model_3.history[validation_metric], label='validation')\n",
    "\n",
    "            ax2.tick_params(\n",
    "            axis='y',\n",
    "            which='both',   \n",
    "            left=False\n",
    "            )  \n",
    "\n",
    "            axes_list = [ax1, ax2, ax3]\n",
    "\n",
    "        for ax in axes_list:\n",
    "            if epochs <= 20:\n",
    "                ax.set_xticks(np.arange(epochs), np.arange(1, epochs+1))\n",
    "            else:\n",
    "                original_ticks_list = np.arange(epochs)\n",
    "                # Just 3 ticks (min, half, max)\n",
    "                new_ticks_list = [min(original_ticks_list), original_ticks_list[math.floor(len(original_ticks_list)/2)], max(original_ticks_list)]\n",
    "                new_ticks_label_list = [min(original_ticks_list+1), original_ticks_list[math.floor(len(original_ticks_list)/2)], max(original_ticks_list)+1]\n",
    "                ax.set_xticks(new_ticks_list, new_ticks_label_list)\n",
    "            \n",
    "            ax.set_xlabel('Epoch')\n",
    "            ax.set_ylabel(ylabel)\n",
    "            ax.legend(loc='best')\n",
    "            ax.grid()\n",
    "\n",
    "            ax.tick_params(\n",
    "                axis='y',\n",
    "                which='both',   \n",
    "                right=False,\n",
    "                labelright=False,\n",
    "                left=True,\n",
    "                labelleft=True,\n",
    "            )\n",
    "\n",
    "# Plot train and validation accuracy of up to three models\n",
    "def plot_cm(model_1, model_2=None, model_3=None, dataset=train, title='', subtitle_1='', subtitle_2='', subtitle_3=''):\n",
    "    X_train, Y_train = dataset\n",
    "    labels = Y_train #Rename just for the sake of understanding\n",
    "\n",
    "    if model_2 is None and model_3 is None:\n",
    "        predictions = np.argmax(model_1.predict(X_train), axis=-1)\n",
    "        \n",
    "        print(' - Accuracy:', accuracy_score(labels, predictions))\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(7,5))\n",
    "        ax = sns.heatmap(confusion_matrix(labels, predictions), cmap='Blues', annot=True, fmt='.0f', cbar=True, xticklabels=LABELS_TEXT, yticklabels=LABELS_TEXT)\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Predicted class') \n",
    "        plt.ylabel('True class') \n",
    "        \n",
    "    else:\n",
    "        if model_3 is None:\n",
    "            predictions_model_1 = np.argmax(model_1.predict(X_train), axis=-1)\n",
    "            predictions_model_2 = np.argmax(model_2.predict(X_train), axis=-1)\n",
    "\n",
    "            print(' -', subtitle_1,'Accuracy:', accuracy_score(labels, predictions_model_1))\n",
    "            print(' -', subtitle_2,'Accuracy:', accuracy_score(labels, predictions_model_2))\n",
    "\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15.3,5))\n",
    "            fig.suptitle(title)\n",
    "            ax1.title.set_text(subtitle_1)\n",
    "            ax2.title.set_text(subtitle_2)\n",
    "            axes_list = [ax1, ax2]\n",
    "            g1 = sns.heatmap(confusion_matrix(labels, predictions_model_1), cmap='Blues', annot=True, fmt='.0f', cbar=True, xticklabels=LABELS_TEXT, yticklabels=LABELS_TEXT, ax=ax1)\n",
    "            g2 = sns.heatmap(confusion_matrix(labels, predictions_model_2), cmap='Blues', annot=True, fmt='.0f', cbar=True, xticklabels=LABELS_TEXT, yticklabels=LABELS_TEXT, ax=ax2)\n",
    "\n",
    "        else:\n",
    "            predictions_model_1 = np.argmax(model_1.predict(X_train), axis=-1)\n",
    "            predictions_model_2 = np.argmax(model_2.predict(X_train), axis=-1)\n",
    "            predictions_model_3 = np.argmax(model_3.predict(X_train), axis=-1)\n",
    "\n",
    "            print(' -', subtitle_1,'Accuracy:', accuracy_score(labels, predictions_model_1))\n",
    "            print(' -', subtitle_2,'Accuracy:', accuracy_score(labels, predictions_model_2))\n",
    "            print(' -', subtitle_3,'Accuracy:', accuracy_score(labels, predictions_model_3))\n",
    "\n",
    "            fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24,5))\n",
    "            fig.suptitle(title)\n",
    "            ax1.title.set_text(subtitle_1)\n",
    "            ax2.title.set_text(subtitle_2)\n",
    "            ax3.title.set_text(subtitle_3)\n",
    "            axes_list = [ax1, ax2, ax3]\n",
    "            g1 = sns.heatmap(confusion_matrix(labels, predictions_model_1), cmap='Blues', annot=True, fmt='.0f', cbar=True, xticklabels=LABELS_TEXT, yticklabels=LABELS_TEXT, ax=ax1)\n",
    "            g2 = sns.heatmap(confusion_matrix(labels, predictions_model_2), cmap='Blues', annot=True, fmt='.0f', cbar=True, xticklabels=LABELS_TEXT, yticklabels=LABELS_TEXT, ax=ax2)\n",
    "            g3 = sns.heatmap(confusion_matrix(labels, predictions_model_3), cmap='Blues', annot=True, fmt='.0f', cbar=True, xticklabels=LABELS_TEXT, yticklabels=LABELS_TEXT, ax=ax3)\n",
    "\n",
    "        for ax in axes_list:\n",
    "            ax.set_xlabel('Predicted class')\n",
    "            ax.set_ylabel('True class')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTES\n",
    "\n",
    "LABELS = np.unique(Y_train).tolist()\n",
    "LABELS_TEXT = ['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
    "INPUTS = 28*28\n",
    "OUTPUTS = len(LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RED MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS\n",
    "\n",
    "mlp_3l_100 = Sequential([\n",
    "    Rescaling(1/255, input_shape=(28,28,1)),\n",
    "    Flatten(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(OUTPUTS, activation='softmax'),\n",
    "])\n",
    "\n",
    "mlp_3l_100.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "\n",
    "mlp_3l_100.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_3l_100_e10 = fit_model(mlp_3l_100, epochs=10)\n",
    "mlp_3l_100_e20 = fit_model(mlp_3l_100, epochs=20)\n",
    "mlp_3l_100_e30 = fit_model(mlp_3l_100, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_3l_10 = Sequential([\n",
    "    Rescaling(1/255, input_shape=(28,28,1)),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(OUTPUTS, activation='softmax'),\n",
    "])\n",
    "\n",
    "mlp_3l_10.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")\n",
    "\n",
    "mlp_3l_10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_3l_10_fit = fit_model(mlp_3l_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model_1=mlp_3l_10_fit, title=\"MLP TEST NO. 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSFER LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.Xception(\n",
    "    weights='imagenet',  \n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze the base model layers\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the final dense layer\n",
    "inputs = tf.keras.Input(shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential(\n",
    "    [       \n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "x = data_augmentation(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.applications.xception.preprocess_input(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- ensure that the base model is running in inference mode so that batch normalization layers are not updated during the fine-tuning stage (set `training=False`);\n",
    "- convert features from the base model to vectors, using `GlobalAveragePooling2D`;\n",
    "- apply dropout regularization;\n",
    "- add a final dense layer (when you used `include_top=False,` the final output layer was not included, so you have to define your own).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model(x, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)  \n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),metrics=tf.keras.metrics.BinaryAccuracy())\n",
    "model.fit(X_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6de9176f41d17a630063e39ec53a28277e92eb8562e5d328a4b9ee1e56a1825"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
