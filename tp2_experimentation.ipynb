{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y Evaluación de Modelos\n",
    "\n",
    "## Trabajo Práctico Nro. 2 - Grupo 3\n",
    "\n",
    "#### Integrantes:\n",
    "* Ignacio Busso\n",
    "* Lucas Copes\n",
    "* Jesica Heit\n",
    "\n",
    "#### Dataset: https://www.kaggle.com/datasets/teejmahal20/airline-passenger-satisfaction\n",
    "* Detalle: contiene datos de la satisfacción de los pasajeros de diferentes vuelos tomando en cuenta multiples aspectos (calidad del servicio, comodidad, limpieza, etc.)\n",
    "* Target: columna 'satisfaction', para determinar la satisfacción de un pasajero respecto a un vuelo.\n",
    "* Dimensiones: 25 columnas x 129.880 filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "pd.options.display.max_columns = 0\n",
    "\n",
    "#Cambios en el estilo de los graficos\n",
    "plt.style.use('fast')\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura y concatenación de los .csv\n",
    "train = pd.read_csv('data/train.csv', index_col=[0])\n",
    "test = pd.read_csv('data/test.csv', index_col=[0])\n",
    "all_data = pd.concat([train, test], sort=False)\n",
    "\n",
    "# Asignamos nuevos nombres a algunas de las columnas\n",
    "new_column_names = {\n",
    "    'Gender': 'gender',\n",
    "    'Customer Type': 'customer_type',\n",
    "    'Age': 'age',\n",
    "    'Type of Travel': 'business_travel',\n",
    "    'Class': 'ticket_class',\n",
    "    'Flight Distance': 'flight_distance',\n",
    "    'Inflight wifi service': 'wifi_service',\n",
    "    'Departure/Arrival time convenient': 'departure_arrival_time_convenient',\n",
    "    'Ease of Online booking': 'online_booking',\n",
    "    'Gate location': 'gate_location',\n",
    "    'Food and drink': 'food_and_drink',\n",
    "    'Online boarding': 'online_boarding',\n",
    "    'Seat comfort': 'seat_comfort',\n",
    "    'Inflight entertainment': 'inflight_entertainment',\n",
    "    'On-board service': 'onboard_service',\n",
    "    'Leg room service': 'leg_room',\n",
    "    'Baggage handling': 'baggage_handling',\n",
    "    'Checkin service': 'checkin',\n",
    "    'Inflight service': 'inflight_service',\n",
    "    'Cleanliness': 'cleanliness',\n",
    "    'Departure Delay in Minutes': 'departure_delay',\n",
    "    'Arrival Delay in Minutes': 'arrival_delay',\n",
    "}\n",
    "\n",
    "all_data.rename(columns=new_column_names, inplace=True)\n",
    "all_data.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocesado\n",
    "1. Conversión de variables cualitativas a booleanas cuantitativas.\n",
    "2. \n",
    "    - Limpieza de registros con nulos implícitos en los servicios. Aplica solo a filas con menos de 500 casos.\n",
    "    - Limpieza de registros NaN en arrival_delays\n",
    "3. Limpieza de valores extremos en arrival_delays y departure_delays. (~600 registros)\n",
    "4. Limpieza de valores extremos en flight_distance. Aplica solo a vuelos de más de 4000 unidades de longitud (~75 registros)\n",
    "5. Feature Engineering creando intervalos para cuatro variables numéricas. (`age`, `flight_distance`, `departure_delay` y `arrival_delay`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversión a variables booleanas\n",
    "all_data['gender'] = all_data['gender'].replace(['Male','Female'],[0,1])\n",
    "all_data['customer_type'] = all_data['customer_type'].replace(['disloyal Customer','Loyal Customer'],[0,1])\n",
    "all_data['business_travel'] = all_data['business_travel'].replace(['Personal Travel','Business travel'],[0,1])\n",
    "all_data['satisfaction'] = all_data['satisfaction'].replace(['neutral or dissatisfied','satisfied'],[0,1])\n",
    "\n",
    "# Limpieza de filas con pocas (< 500) features de servicios nulas (== 0) y arrivals NaNs\n",
    "all_data = all_data[\n",
    "    ~(all_data == 0).gate_location &\n",
    "    ~(all_data == 0).food_and_drink &\n",
    "    ~(all_data == 0).seat_comfort & \n",
    "    ~(all_data == 0).inflight_entertainment &\n",
    "    ~(all_data == 0).onboard_service &\n",
    "    ~(all_data == 0).checkin &\n",
    "    ~(all_data == 0).inflight_service &\n",
    "    ~(all_data == 0).cleanliness &\n",
    "    ~all_data.arrival_delay.isnull()\n",
    "    ]\n",
    "\n",
    "# Limpieza de valores extremos en Arrivals y Departures\n",
    "all_data = all_data.drop(all_data[all_data.arrival_delay > 240].index)\n",
    "all_data = all_data.drop(all_data[all_data.departure_delay > 240].index)\n",
    "\n",
    "# Limpieza de valores extremos en flight_distance (> 4000 - 75 registros)\n",
    "all_data = all_data.drop(all_data[all_data.flight_distance > 4000].index)\n",
    "\n",
    "# Creación de intervalos para features numéricas\n",
    "    # Puede ser visto como Binning / Redondeo de números? Feature Engineering?\n",
    "    # Ver de dejarlo para el final. Ejecutarlo por separado en otro df y comparar resultados.\n",
    "\n",
    "# ¿Corresponde que los labels tengan como nombre el mayor numero del intervalo? ¿Debería usar un valor calculado en su lugar? (Media/Mediana/Moda)\n",
    "all_data[\"age_interval\"] = pd.cut(x=all_data['age'], bins=[0,12,18,30,60,80,100], labels=[12,18,30,60,80,100])\n",
    "all_data[\"flight_distance_interval\"] = pd.cut(x=all_data['flight_distance'], bins=[0,500,1000,1500,2000,2500,3000,3500,4000,4500,5000], labels=[500,1000,1500,2000,2500,3000,3500,4000,4500,5000])\n",
    "all_data[\"departure_delay_interval\"] = pd.cut(x=all_data['departure_delay'], bins=[-1,0,15,30,45,60,120,180,240], labels=[0,15,30,45,60,120,180,240])\n",
    "all_data[\"arrival_delay_interval\"] = pd.cut(x=all_data['arrival_delay'], bins=[-1,0,15,30,45,60,120,180,240], labels=[0,15,30,45,60,120,180,240])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Armado de datasets\n",
    "- 60% Train         (77k)\n",
    "- 20% Validation    (25k)\n",
    "- 20% Test          (25k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, not_train = train_test_split(all_data, test_size=0.4, random_state=7)\n",
    "validation, test = train_test_split(not_train, test_size=0.5, random_state=7)\n",
    "\n",
    "train.shape, validation.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrameMapper\n",
    "- Escalar todas las variables numéricas no booleanas con MinMaxScaler (valores entre 0-1).\n",
    "- Imputar las features con más de 600 nulos con IterativeImputer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Imputar y escalar\n",
    "mapper = DataFrameMapper([\n",
    "    (['gender'], None),\n",
    "    (['customer_type'], None),\n",
    "    (['age_interval'], [MinMaxScaler()]),\n",
    "    (['business_travel'], None),\n",
    "    (['ticket_class'], [OneHotEncoder()]),\n",
    "    (['flight_distance_interval'], [MinMaxScaler()]),\n",
    "    (['wifi_service'], [IterativeImputer(missing_values=0), MinMaxScaler()]),\n",
    "    (['departure_arrival_time_convenient'], [IterativeImputer(missing_values=0), MinMaxScaler()]),\n",
    "    (['online_booking'], [IterativeImputer(missing_values=0), MinMaxScaler()]),\n",
    "    (['gate_location'], [MinMaxScaler()]),\n",
    "    (['food_and_drink'], [MinMaxScaler()]),\n",
    "    (['online_boarding'], [IterativeImputer(missing_values=0), MinMaxScaler()]),\n",
    "    (['seat_comfort'], [MinMaxScaler()]),\n",
    "    (['inflight_entertainment'], [MinMaxScaler()]),\n",
    "    (['onboard_service'], [MinMaxScaler()]),\n",
    "    (['leg_room'], [IterativeImputer(missing_values=0), MinMaxScaler()]),\n",
    "    (['baggage_handling'], [MinMaxScaler()]),\n",
    "    (['checkin'], [MinMaxScaler()]),\n",
    "    (['inflight_service'], [MinMaxScaler()]),\n",
    "    (['cleanliness'], [MinMaxScaler()]),\n",
    "    (['departure_delay_interval'], [MinMaxScaler()]),\n",
    "    (['arrival_delay_interval'], [MinMaxScaler()]),\n",
    "    (['satisfaction'], None)\n",
    "], df_out=True)\n",
    "\n",
    "mapper.fit(all_data)\n",
    "#mfit = mapper.fit(all_data)\n",
    "#all_data_transformed = mapper.transform(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformación de un sample:\n",
    "sample = all_data.sample(7, random_state=7)\n",
    "# Sample original:\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample transformado.\n",
    "mapper.transform(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombres de los features\n",
    "mapper.transformed_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('mapper', mapper),\n",
    "    ('imputer', IterativeImputer()),\n",
    "])\n",
    "# Lo entrenamos con train\n",
    "pipe.fit(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.transform(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejemplo IterativeImputer\n",
    "\n",
    "entradas = np.array((\n",
    "    (20, 1, 200),\n",
    "    (10, 1, 0),\n",
    "    (30, 3, 1),\n",
    "    (20, 2, 1),\n",
    "    (10, 2, 23),\n",
    "))\n",
    "\n",
    "imputador = IterativeImputer(missing_values=0)\n",
    "imputador.fit_transform(entradas)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e1f9169ae4315cfc4614565a4c2b2d600515b6454333995dfdf26296b7266cb1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
