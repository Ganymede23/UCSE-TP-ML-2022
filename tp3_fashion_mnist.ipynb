{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests GPU local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPUs:\", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de python, para especificar rutas de archivos y directorios\n",
    "from pathlib import Path\n",
    "\n",
    "# lib para trabajar con arrays\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# lib que usamos para mostrar las imágenes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# libs que usamos para construir y entrenar redes neuronales, y que además tiene utilidades para leer sets de \n",
    "# imágenes\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Convolution2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "\n",
    "# libs que usamos para tareas generales de machine learning. En este caso, métricas\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# configuración para que las imágenes se vean dentro del notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "train, test = fashion_mnist.load_data()\n",
    "(X_train, Y_train) = train \n",
    "(X_test, Y_test) = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTES\n",
    "\n",
    "LABELS = np.unique(Y_train).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "El dataset se divide en un set de train con 60.000 ejemplos, y un set de test con otros 10.000. Cada ejemplo consta de una imagen en escala de grises de 28x28 pixeles (784 en total), asociado a una etiqueta de 10 clases.\n",
    "Cada pixel es representado por un solo valor, indicando el nivel de brillo u obscuridad en él. Estos valores van entre 0 y 255.\n",
    "\n",
    "### Etiquetas\n",
    "- 0 - T-shirt/top\n",
    "- 1 - Trouser\n",
    "- 2 - Pullover\n",
    "- 3 - Dress\n",
    "- 4 - Coat\n",
    "- 5 - Sandal\n",
    "- 6 - Shirt\n",
    "- 7 - Sneaker\n",
    "- 8 - Bag\n",
    "- 9 - Ankle boot\n",
    "\n",
    "Las dimensiones de las imágenes pueden apreciarse al hacer un `.shape` de los datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:', X_train.shape)\n",
    "print('Test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(dataset): \n",
    "    # specify the number of rows and columns you want to see\n",
    "    num_row = 3\n",
    "    num_col = 3\n",
    "\n",
    "    # get a segment of the dataset\n",
    "    num = num_row*num_col\n",
    "    if dataset == train:\n",
    "        images, labels = X_train[:num], Y_train[:num]\n",
    "    else: # Test dataset\n",
    "        images, labels = X_test[:num], Y_test[:num]\n",
    "\n",
    "    # plot images\n",
    "    fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i], cmap='gray')\n",
    "        plt.title(labels[i])\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "sample_images(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ytrain = pd.DataFrame(data=Y_train)\n",
    "df_ytest = pd.DataFrame(data=Y_test)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(10, 5))\n",
    "fig.suptitle('Distribución de la variable target')\n",
    "ax1.bar([0,1,2,3,4,5,6,7,8,9],df_ytrain.value_counts())\n",
    "ax2.bar([0,1,2,3,4,5,6,7,8,9],df_ytest.value_counts())\n",
    "ax1.set_xticks([0,1,2,3,4,5,6,7,8,9])\n",
    "ax2.set_xticks([0,1,2,3,4,5,6,7,8,9])\n",
    "ax1.title.set_text('Train')\n",
    "ax2.title.set_text('Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable a predecir tiene una **distribución uniforme** en todo ambos datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # el shape de los inputs es alto_imagen * ancho_imagen * cantidad_colores\n",
    "    \n",
    "    Convolution2D(input_shape=(64, 64, 3), filters=8, kernel_size=(4, 4), strides=1, activation='relu'),\n",
    "    # kernels de 4x4x3, y salida de 61x61x8\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Convolution2D(filters=8, kernel_size=(4, 4), strides=1, activation='relu'),\n",
    "    # kernels de 4x4x8, y salida de 58x58x8\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    MaxPooling2D(pool_size=(4, 4)),\n",
    "    # salida de 14x14x8\n",
    "    \n",
    "    Flatten(),\n",
    "    # salida de 1568\n",
    "    \n",
    "    Dense(10, activation='tanh'),\n",
    "    # salida de 10\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(10, activation='tanh'),\n",
    "    # salida de 10\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Dense(len(LABELS), activation='softmax'),\n",
    "    # salida de 3\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy',],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train,\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    validation_data=test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0e32d50fac4f93648707e6c06d16f383ac3ef03705b1d743a12bf83afaecbf40"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
